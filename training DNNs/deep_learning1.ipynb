{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training neural networks\n",
    "In this notebook we exlpore various Keras functions that are helpful for DNN training. We also note some interesting things about them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overly large model\n",
    "dnn = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[32,32,3])\n",
    "])\n",
    "\n",
    "for i in range(20):\n",
    "    dnn.add(keras.layers.Dense(100, activation='elu', kernel_initializer='he_normal'))\n",
    "    \n",
    "dnn.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 107s 1us/step\n"
     ]
    }
   ],
   "source": [
    "dataset = keras.datasets.cifar10.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train_full[:40000]\n",
    "y_train = y_train_full[:40000]\n",
    "X_val = X_train_full[40000:]\n",
    "y_val = y_train_full[40000:]\n",
    "X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early stopping\n",
    "- Probably outdated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 2.9605 - accuracy: 0.2097 - val_loss: 1.9670 - val_accuracy: 0.2583\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.9348 - accuracy: 0.2842 - val_loss: 1.8829 - val_accuracy: 0.3001\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.8653 - accuracy: 0.3114 - val_loss: 1.8350 - val_accuracy: 0.3299\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.8247 - accuracy: 0.3322 - val_loss: 1.8243 - val_accuracy: 0.3346\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.7916 - accuracy: 0.3465 - val_loss: 1.7851 - val_accuracy: 0.3523\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.7651 - accuracy: 0.3571 - val_loss: 1.7951 - val_accuracy: 0.3517\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.7344 - accuracy: 0.3678 - val_loss: 1.7614 - val_accuracy: 0.3644\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.7039 - accuracy: 0.3861 - val_loss: 1.7421 - val_accuracy: 0.3705\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.6739 - accuracy: 0.3940 - val_loss: 1.6824 - val_accuracy: 0.3909\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.6512 - accuracy: 0.4047 - val_loss: 1.6670 - val_accuracy: 0.4091\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.6273 - accuracy: 0.4135 - val_loss: 1.8091 - val_accuracy: 0.3665\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.6067 - accuracy: 0.4232 - val_loss: 1.6451 - val_accuracy: 0.4155\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 1.5852 - accuracy: 0.4292 - val_loss: 1.6365 - val_accuracy: 0.4210\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.5640 - accuracy: 0.4380 - val_loss: 1.6398 - val_accuracy: 0.4122\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 16s 12ms/step - loss: 1.5527 - accuracy: 0.4445 - val_loss: 1.6405 - val_accuracy: 0.4221\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 16s 12ms/step - loss: 1.5327 - accuracy: 0.4505 - val_loss: 1.5995 - val_accuracy: 0.4367\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.5189 - accuracy: 0.4543 - val_loss: 1.5914 - val_accuracy: 0.4383\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 16s 12ms/step - loss: 1.5042 - accuracy: 0.4609 - val_loss: 1.5683 - val_accuracy: 0.4382\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.4907 - accuracy: 0.4640 - val_loss: 1.5970 - val_accuracy: 0.4371\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.4763 - accuracy: 0.4714 - val_loss: 1.5731 - val_accuracy: 0.4437\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.4605 - accuracy: 0.4762 - val_loss: 1.5897 - val_accuracy: 0.4353\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.4577 - accuracy: 0.4787 - val_loss: 1.7056 - val_accuracy: 0.4548\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 16s 12ms/step - loss: 1.4424 - accuracy: 0.4805 - val_loss: 1.5496 - val_accuracy: 0.4575\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.4282 - accuracy: 0.4867 - val_loss: 1.5733 - val_accuracy: 0.4365\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - 16s 12ms/step - loss: 1.4175 - accuracy: 0.4942 - val_loss: 1.5569 - val_accuracy: 0.4485\n",
      "Epoch 26/100\n",
      "1250/1250 [==============================] - 16s 12ms/step - loss: 1.6985 - accuracy: 0.4017 - val_loss: 1.7567 - val_accuracy: 0.3474\n",
      "Epoch 27/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.6861 - accuracy: 0.3793 - val_loss: 1.6889 - val_accuracy: 0.3931\n",
      "Epoch 28/100\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 1.6246 - accuracy: 0.4066 - val_loss: 1.7004 - val_accuracy: 0.3826\n",
      "Epoch 29/100\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 1.5932 - accuracy: 0.4218 - val_loss: 1.6221 - val_accuracy: 0.4165\n",
      "Epoch 30/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.5686 - accuracy: 0.4317 - val_loss: 1.6460 - val_accuracy: 0.4091\n",
      "Epoch 31/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.5501 - accuracy: 0.4382 - val_loss: 1.6322 - val_accuracy: 0.4071\n",
      "Epoch 32/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.5341 - accuracy: 0.4429 - val_loss: 1.6263 - val_accuracy: 0.4207\n",
      "Epoch 33/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.5242 - accuracy: 0.4469 - val_loss: 1.5680 - val_accuracy: 0.4347\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5680 - accuracy: 0.4347\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5680395364761353, 0.43470001220703125]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(lr=5e-4)\n",
    "dnn.compile(optimizer=optimizer, \n",
    "            loss=keras.losses.sparse_categorical_crossentropy, \n",
    "            metrics=['accuracy'], \n",
    "            )\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10)\n",
    "dnn.fit(X_train, y_train,  epochs=100,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks = [early_stopping_cb]\n",
    "       )\n",
    "dnn.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Normalization\n",
    "\n",
    "- Note: this is essentially scaling the data *on all layers* which enourmously helps gradient descent. Therefore: BatchNorm layers are included in almost every architecture now (ex. Transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn2 = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[32,32,3])\n",
    "])\n",
    "\n",
    "for i in range(20):\n",
    "    dnn2.add(keras.layers.BatchNormalization())\n",
    "    dnn2.add(keras.layers.Dense(100, activation='elu', kernel_initializer='he_normal'))\n",
    "    \n",
    "dnn2.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1250/1250 [==============================] - 21s 17ms/step - loss: 1.9431 - accuracy: 0.3015 - val_loss: 1.7523 - val_accuracy: 0.3659\n",
      "Epoch 2/30\n",
      "1250/1250 [==============================] - 21s 17ms/step - loss: 1.7417 - accuracy: 0.3784 - val_loss: 1.6397 - val_accuracy: 0.4149\n",
      "Epoch 3/30\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 1.6646 - accuracy: 0.4096 - val_loss: 1.5739 - val_accuracy: 0.4448\n",
      "Epoch 4/30\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 1.6101 - accuracy: 0.4283 - val_loss: 1.5421 - val_accuracy: 0.4526\n",
      "Epoch 5/30\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 1.5612 - accuracy: 0.4505 - val_loss: 1.5358 - val_accuracy: 0.4576\n",
      "Epoch 6/30\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 1.5295 - accuracy: 0.4576 - val_loss: 1.4999 - val_accuracy: 0.4726\n",
      "Epoch 7/30\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 1.4956 - accuracy: 0.4713 - val_loss: 1.5275 - val_accuracy: 0.4653\n",
      "Epoch 8/30\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 1.4575 - accuracy: 0.4836 - val_loss: 1.4433 - val_accuracy: 0.4928\n",
      "Epoch 9/30\n",
      "1250/1250 [==============================] - 21s 17ms/step - loss: 1.4357 - accuracy: 0.4945 - val_loss: 1.4429 - val_accuracy: 0.4865\n",
      "Epoch 10/30\n",
      "1250/1250 [==============================] - 21s 17ms/step - loss: 1.4062 - accuracy: 0.5069 - val_loss: 1.4677 - val_accuracy: 0.4856\n",
      "Epoch 11/30\n",
      "1250/1250 [==============================] - 21s 16ms/step - loss: 1.3751 - accuracy: 0.5145 - val_loss: 1.4593 - val_accuracy: 0.4839\n",
      "Epoch 12/30\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 1.3604 - accuracy: 0.5222 - val_loss: 1.4019 - val_accuracy: 0.5108\n",
      "Epoch 13/30\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 1.3292 - accuracy: 0.5332 - val_loss: 1.4159 - val_accuracy: 0.4975\n",
      "Epoch 14/30\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 1.3138 - accuracy: 0.5399 - val_loss: 1.3745 - val_accuracy: 0.5195\n",
      "Epoch 15/30\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 1.2948 - accuracy: 0.5475 - val_loss: 1.4031 - val_accuracy: 0.5073\n",
      "Epoch 16/30\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 1.2714 - accuracy: 0.5518 - val_loss: 1.3900 - val_accuracy: 0.5159\n",
      "Epoch 17/30\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 1.2601 - accuracy: 0.5598 - val_loss: 1.3796 - val_accuracy: 0.5186\n",
      "Epoch 18/30\n",
      "1250/1250 [==============================] - 21s 17ms/step - loss: 1.2384 - accuracy: 0.5650 - val_loss: 1.4005 - val_accuracy: 0.5156\n",
      "Epoch 19/30\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 1.2207 - accuracy: 0.5731 - val_loss: 1.3624 - val_accuracy: 0.5233\n",
      "Epoch 20/30\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 1.2065 - accuracy: 0.5778 - val_loss: 1.3583 - val_accuracy: 0.5353\n",
      "Epoch 21/30\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 1.1882 - accuracy: 0.5830 - val_loss: 1.3808 - val_accuracy: 0.5184\n",
      "Epoch 22/30\n",
      "1250/1250 [==============================] - 21s 17ms/step - loss: 1.1769 - accuracy: 0.5872 - val_loss: 1.3906 - val_accuracy: 0.5118\n",
      "Epoch 23/30\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 1.1662 - accuracy: 0.5915 - val_loss: 1.3671 - val_accuracy: 0.5275\n",
      "Epoch 24/30\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 1.1441 - accuracy: 0.6007 - val_loss: 1.3994 - val_accuracy: 0.5225\n",
      "Epoch 25/30\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 1.1369 - accuracy: 0.6021 - val_loss: 1.3989 - val_accuracy: 0.5250\n",
      "Epoch 26/30\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 1.1231 - accuracy: 0.6068 - val_loss: 1.3780 - val_accuracy: 0.5313\n",
      "Epoch 27/30\n",
      "1250/1250 [==============================] - 21s 17ms/step - loss: 1.1042 - accuracy: 0.6139 - val_loss: 1.3676 - val_accuracy: 0.5297\n",
      "Epoch 28/30\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 1.0948 - accuracy: 0.6163 - val_loss: 1.3881 - val_accuracy: 0.5300\n",
      "Epoch 29/30\n",
      "1250/1250 [==============================] - 25s 20ms/step - loss: 1.0847 - accuracy: 0.6233 - val_loss: 1.3675 - val_accuracy: 0.5289\n",
      "Epoch 30/30\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 1.0777 - accuracy: 0.6266 - val_loss: 1.3774 - val_accuracy: 0.5330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cb42d59130>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn2.compile(optimizer=\"nadam\", \n",
    "            loss=keras.losses.sparse_categorical_crossentropy, \n",
    "            metrics=['accuracy'], \n",
    "            )\n",
    "dnn2.fit(X_train, y_train,  epochs=30,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks = [keras.callbacks.EarlyStopping(patience=10)]\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_means = X_train.mean(axis=0)\n",
    "X_stds = X_train.std(axis=0)\n",
    "X_train_scaled = (X_train - X_means) / X_stds\n",
    "X_val_scaled = (X_val - X_means) / X_stds\n",
    "X_test_scaled = (X_test - X_means) / X_stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different nonlinearities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 1.9376 - accuracy: 0.3032 - val_loss: 1.7903 - val_accuracy: 0.3711\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.7254 - accuracy: 0.3894 - val_loss: 1.6934 - val_accuracy: 0.3971\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.6292 - accuracy: 0.4233 - val_loss: 1.6822 - val_accuracy: 0.4236\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.5785 - accuracy: 0.4462 - val_loss: 1.6038 - val_accuracy: 0.4362\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.5211 - accuracy: 0.4661 - val_loss: 1.5563 - val_accuracy: 0.4500\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.4748 - accuracy: 0.4851 - val_loss: 1.5592 - val_accuracy: 0.4550\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.4358 - accuracy: 0.4969 - val_loss: 1.5433 - val_accuracy: 0.4594\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.4028 - accuracy: 0.5110 - val_loss: 1.5201 - val_accuracy: 0.4770\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.3661 - accuracy: 0.5248 - val_loss: 1.5486 - val_accuracy: 0.4665\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.3387 - accuracy: 0.5354 - val_loss: 1.5411 - val_accuracy: 0.4824\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.3061 - accuracy: 0.5465 - val_loss: 1.5018 - val_accuracy: 0.4792\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.2857 - accuracy: 0.5549 - val_loss: 1.5402 - val_accuracy: 0.4753\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.2657 - accuracy: 0.5601 - val_loss: 1.5352 - val_accuracy: 0.4896\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.2444 - accuracy: 0.5681 - val_loss: 1.5361 - val_accuracy: 0.4893\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 1.2218 - accuracy: 0.5796 - val_loss: 1.5409 - val_accuracy: 0.4926\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 18s 15ms/step - loss: 1.1948 - accuracy: 0.5894 - val_loss: 1.5365 - val_accuracy: 0.4895\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 1.1741 - accuracy: 0.5969 - val_loss: 1.5320 - val_accuracy: 0.4901\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 1.1596 - accuracy: 0.6015 - val_loss: 1.5361 - val_accuracy: 0.5008\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 1.1384 - accuracy: 0.6119 - val_loss: 1.5780 - val_accuracy: 0.4874\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 1.1147 - accuracy: 0.6182 - val_loss: 1.5638 - val_accuracy: 0.4934\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 1.0904 - accuracy: 0.6291 - val_loss: 1.5820 - val_accuracy: 0.4978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x266cc672610>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SELU\n",
    "dnn3 = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[32,32,3])\n",
    "])\n",
    "\n",
    "for i in range(20):\n",
    "    dnn3.add(keras.layers.Dense(100, activation='selu', kernel_initializer='lecun_normal'))\n",
    "    \n",
    "dnn3.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(lr=8e-4)\n",
    "dnn3.compile(optimizer=optimizer, \n",
    "            loss=keras.losses.sparse_categorical_crossentropy, \n",
    "            metrics=['accuracy'], \n",
    "            )\n",
    "cb = keras.callbacks.EarlyStopping(patience=10)\n",
    "\n",
    "\n",
    "\n",
    "dnn3.fit(X_train_scaled, y_train,  epochs=100,\n",
    "        validation_data=(X_val_scaled, y_val),\n",
    "        callbacks = [cb]\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(lr=1e-2, decay=)\n",
    "dnn.compile(optimizer=optimizer, \n",
    "            loss=keras.losses.sparse_categorical_crossentropy, \n",
    "            metrics=['accuracy'], \n",
    "            )\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10)\n",
    "dnn.fit(X_train, y_train,  epochs=100,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks = [early_stopping_cb]\n",
    "       )\n",
    "dnn.evaluate(X_val, y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
